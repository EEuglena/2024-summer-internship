{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "import torch\n",
    "import e3nn\n",
    "import numpy as np\n",
    "import random\n",
    "from datetime import datetime\n",
    "from torch_geometric.datasets import MD17\n",
    "from model import InteractionModel\n",
    "from dataloader import InteractionDataLoader\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    message=\"The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constants\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "# Dataloader\n",
    "TRAIN_SIZE = 25000  # NOTE\n",
    "EVAL_SIZE = 1000\n",
    "TEST_SIZE = 10000\n",
    "\n",
    "# Model\n",
    "# - Atomic\n",
    "MAX_Z = 10\n",
    "DIM_ATOMS = 30\n",
    "IRREPS_ATOM = e3nn.o3.Irreps(f\"{DIM_ATOMS}x0e\")\n",
    "# - Distance\n",
    "# NOTE\n",
    "MU_MIN = 0.0\n",
    "MU_MAX = 10.0\n",
    "STEP = 0.5\n",
    "R_CUT = 10.0\n",
    "DIM_R = int(np.ceil((MU_MAX - MU_MIN) / STEP) + 1)\n",
    "IRREPS_R = e3nn.o3.Irreps(f\"{DIM_R}x0e\")\n",
    "IRREPS_SH = e3nn.o3.Irreps.spherical_harmonics(2)\n",
    "# - Readout\n",
    "DIM_MID = 15\n",
    "# - Layer\n",
    "N_INTERACTIONS = 3\n",
    "\n",
    "# Trainer\n",
    "N_EPOCHS = 1000\n",
    "LEARNING_RATE = 1e-3\n",
    "WEIGHT_DECAY = 1e-3\n",
    "EARLY_STOP_THRESHOLD = 10  # NOTE\n",
    "MIN_EPOCHS = 5\n",
    "\n",
    "DATASETS_PATH = \"datasets\"\n",
    "CHECKPOINT_PATH = \"MD17_toluene_model.pt\"\n",
    "TARGET_MOLECULE = \"revised toluene\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(predict, label):\n",
    "    return (predict - label) ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_rotation(device, data):\n",
    "    random_mat = e3nn.o3.rand_matrix().to(device)\n",
    "    data.update({\"pos\": data[\"pos\"] @ random_mat.T})\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate model\n",
    "model = InteractionModel(\n",
    "    device=device,\n",
    "    activation_fn=torch.nn.SiLU(),\n",
    "    r_cut=R_CUT,\n",
    "    max_z=MAX_Z,\n",
    "    dim_atoms=DIM_ATOMS,\n",
    "    dim_mid=DIM_MID,\n",
    "    mu_min=MU_MIN,\n",
    "    mu_max=MU_MAX,\n",
    "    step=STEP,\n",
    "    irreps_r=IRREPS_R,\n",
    "    irreps_sh=IRREPS_SH,\n",
    "    irreps_atom=IRREPS_ATOM,\n",
    "    n_interactions=N_INTERACTIONS,\n",
    "    energy_conversion=lambda x: x,\n",
    ")\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY\n",
    ")\n",
    "# TODO scheduler\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(\n",
    "    optimizer=optimizer, lr_lambda=lambda epoch: 0.95**epoch\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = \"single\"\n",
    "assert mode in [\"single\", \"multiple\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "if mode == \"single\":\n",
    "    # TODO QM9\n",
    "    raw_data = MD17(DATASETS_PATH, TARGET_MOLECULE).to(device)\n",
    "    idx = random.sample(\n",
    "        np.arange(len(raw_data)).tolist(), TRAIN_SIZE + EVAL_SIZE + TEST_SIZE\n",
    "    )\n",
    "    idx = np.split(\n",
    "        idx, [TRAIN_SIZE, TRAIN_SIZE + EVAL_SIZE, TRAIN_SIZE + EVAL_SIZE + TEST_SIZE]\n",
    "    )\n",
    "    train_idx = idx[0]\n",
    "    np.random.shuffle(train_idx)\n",
    "    eval_idx = idx[1]\n",
    "    test_idx = idx[2]\n",
    "    train_dataset = InteractionDataLoader(raw_data[train_idx])\n",
    "    eval_dataset = InteractionDataLoader(raw_data[eval_idx])\n",
    "    test_dataset = InteractionDataLoader(raw_data[test_idx])\n",
    "elif mode == \"multiple\":\n",
    "    # TODO\n",
    "    train_molecules = [\n",
    "        \"revised toluene\",\n",
    "        \"revised salicylic acid\",\n",
    "        \"revised paracetamol\",\n",
    "        \"revised aspirin\",\n",
    "        \"revised azobenzene\",\n",
    "        \"revised benzene\",\n",
    "        \"revised uracil\",\n",
    "        \"revised naphthalene\",\n",
    "        \"revised malonaldehyde\",\n",
    "        \"revised ethanol\",\n",
    "    ]\n",
    "    raw_datasets = [\n",
    "        MD17(DATASETS_PATH, molecule).to(device)\n",
    "        for molecule in train_molecules\n",
    "        if molecule != TARGET_MOLECULE\n",
    "    ]\n",
    "    indices = [\n",
    "        random.sample(np.arange(len(raw_dataset)).tolist(), TRAIN_SIZE + EVAL_SIZE)\n",
    "        for raw_dataset in raw_datasets\n",
    "    ]\n",
    "    indices = [\n",
    "        np.split(index, [TRAIN_SIZE, TRAIN_SIZE + EVAL_SIZE]) for index in indices\n",
    "    ]\n",
    "    train_dataset = [\n",
    "        [\n",
    "            {**data.to_dict(), \"name\": raw_datasets[i].name}\n",
    "            for data in raw_datasets[i][index[0]]\n",
    "        ]\n",
    "        for (i, index) in enumerate(indices)\n",
    "    ]\n",
    "    train_dataset = [item for subset in train_dataset for item in subset]\n",
    "    np.random.shuffle(train_dataset)\n",
    "    eval_dataset = [\n",
    "        [\n",
    "            {**data.to_dict(), \"name\": raw_datasets[i].name}\n",
    "            for data in raw_datasets[i][index[1]]\n",
    "        ]\n",
    "        for (i, index) in enumerate(indices)\n",
    "    ]\n",
    "    eval_dataset = [item for subset in eval_dataset for item in subset]\n",
    "\n",
    "    test_molecule = TARGET_MOLECULE\n",
    "    test_dataset = MD17(DATASETS_PATH, test_molecule).to(device)\n",
    "    test_indices = random.sample(np.arange(len(test_dataset)).tolist(), TEST_SIZE)\n",
    "    test_dataset = InteractionDataLoader(test_dataset[test_indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run train and evalutaion loop\n",
    "train_loss = []\n",
    "eval_loss = []\n",
    "best_loss = torch.inf\n",
    "best_plot = []\n",
    "\n",
    "early_stop_counter = 0\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    model.train()\n",
    "    train_loss.append([])\n",
    "    plot = []\n",
    "    for i, batch in enumerate(\n",
    "        tqdm(train_dataset, desc=f\"Epoch #{epoch + 1:02} (Train)\")\n",
    "    ):\n",
    "        data, readout = model(batch)\n",
    "        loss = loss_fn(data[\"e\"], readout)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        plot.append((data[\"e\"].item(), readout.item(), data[\"name\"]))\n",
    "\n",
    "        train_loss[-1].append(loss.item())\n",
    "    scheduler.step()\n",
    "\n",
    "    eval_loss.append([])\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(\n",
    "            tqdm(eval_dataset, desc=f\"Epoch #{epoch + 1:02} (Valid)\")\n",
    "        ):\n",
    "            data, readout = model(batch)\n",
    "            loss = loss_fn(data[\"e\"], readout)\n",
    "            eval_loss[-1].append(loss.item())\n",
    "\n",
    "    if epoch > MIN_EPOCHS:\n",
    "        if np.mean(eval_loss[-1]) < best_loss:\n",
    "            best_loss = np.mean(eval_loss[-1])\n",
    "            best_plot = plot\n",
    "            torch.save(\n",
    "                {\n",
    "                    \"epoch\": epoch,\n",
    "                    \"model_state_dict\": model.state_dict(),\n",
    "                    \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "                    \"loss\": best_loss,\n",
    "                },\n",
    "                CHECKPOINT_PATH,\n",
    "            )\n",
    "            early_stop_counter = 0\n",
    "        else:\n",
    "            early_stop_counter += 1\n",
    "\n",
    "        if early_stop_counter > EARLY_STOP_THRESHOLD:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load checkpoint\n",
    "checkpoint = torch.load(CHECKPOINT_PATH)\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "epoch = checkpoint[\"epoch\"]\n",
    "loss = checkpoint[\"loss\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test model\n",
    "test_plot = []\n",
    "test_loss = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i, batch in enumerate(tqdm(test_dataset)):\n",
    "        data, readout = model(batch)\n",
    "        test_plot.append([data[\"e\"].item(), readout.item()])\n",
    "        test_loss.append(loss_fn(data[\"e\"].item(), readout.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 10))\n",
    "axes = fig.subplots(2, 2)\n",
    "\n",
    "\n",
    "axes[0][0].plot([x[0] for x in test_plot], label=\"Label\")\n",
    "axes[0][0].plot([x[1] for x in test_plot], label=\"Model\", alpha=0.5)\n",
    "axes[0][0].legend()\n",
    "axes[0][0].set_title(\"Inference test\")\n",
    "\n",
    "if mode == \"single\":\n",
    "    axes[0][1].plot([x[0] for x in best_plot], label=\"Label\")\n",
    "    axes[0][1].plot([x[1] for x in best_plot], label=\"Model\", alpha=0.5)\n",
    "    axes[0][1].legend()\n",
    "    axes[0][1].set_title(\"Best Training Epoch\")\n",
    "elif mode == \"multiple\":\n",
    "    plot_dict = dict()\n",
    "    for x in best_plot:\n",
    "        if x[2] in plot_dict:\n",
    "            plot_dict[x[2]].append((x[0], x[1]))\n",
    "        else:\n",
    "            plot_dict[x[2]] = [(x[0], x[1])]\n",
    "    for k, v in plot_dict.items():\n",
    "        axes[0][1].scatter(\n",
    "            [x[0] for x in v],\n",
    "            [x[1] for x in v],\n",
    "            alpha=1.0,\n",
    "            label=k.split(\"revised \")[-1],\n",
    "        )\n",
    "    axes[0][1].scatter(\n",
    "        [x[0] for x in test_plot],\n",
    "        [x[1] for x in test_plot],\n",
    "        alpha=1.0,\n",
    "        label=f\"test, {test_molecule.split('revised ')[-1]}\",\n",
    "    )\n",
    "    axes[0][1].legend()\n",
    "    axes[0][1].set_title(\"Scatter Plot\")\n",
    "\n",
    "axes[1][0].plot([np.log(np.mean(loss)) for loss in train_loss], label=\"train loss\")\n",
    "axes[1][0].plot([np.log(np.mean(loss)) for loss in eval_loss], label=\"eval loss\")\n",
    "axes[1][0].legend()\n",
    "axes[1][0].set_title(\"log(Loss)\")\n",
    "\n",
    "axes[1][1].plot(train_loss[epoch], label=f\"Epoch {epoch:02}\")\n",
    "axes[1][1].legend()\n",
    "axes[1][1].set_title(\"Best train loss\")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Best train loss : {loss:.2e} (MSE, kcal/mol)\")\n",
    "print(f\"Test loss       : {np.mean(test_loss):.2e} (MSE, kcal/mol)\")\n",
    "print()\n",
    "print(f\"Test Error      : {(np.mean(test_loss) ** 0.5):.2e} kcal/mol\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"Parameters in model : {sum([p.numel() for p in model.parameters() if p.requires_grad])}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_test = best_plot\n",
    "print(f\"Train R2 : {r2_score([x[0] for x in r2_test], [x[1] for x in r2_test])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_test = test_plot\n",
    "print(f\"Test R2 : {r2_score([x[0] for x in r2_test], [x[1] for x in r2_test])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"_\".join(TARGET_MOLECULE.split())\n",
    "rmse = torch.tensor(test_loss) ** 0.5\n",
    "std, mean = torch.std_mean(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.now()\n",
    "date = f\"{now.year}/{now.month:02}/{now.day:02}\"\n",
    "report = f\"{name}({TRAIN_SIZE//1000}k) : {mean.item():.2f} Â± {std.item():.2f} [kcal/mol]  {date}\\n\"\n",
    "report_path = \"MD17_report.txt\"\n",
    "with open(report_path, \"a\", encoding=\"UTF-8\") as report_file:\n",
    "    report_file.write(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
